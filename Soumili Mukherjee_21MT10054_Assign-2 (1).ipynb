{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86bc756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.preprocessing import LabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c55b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ab4d20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "digit_mnist = keras.datasets.mnist\n",
    "(Xtrain,Ytrain),(Xtest,Ytest)=digit_mnist.load_data() #spilt the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d5ea63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data:  (60000, 28, 28)\n",
      "Shape of test data:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training data: \",Xtrain.shape)\n",
    "print(\"Shape of test data: \",Xtest.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f26d9379",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the feature values\n",
    "Xtrain = Xtrain.astype(\"float32\")/255.0\n",
    "Xtest = Xtest.astype(\"float32\")/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "324ea500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the labels from integer to vector\n",
    "Ytrain = LabelBinarizer().fit_transform(Ytrain)\n",
    "Ytest = LabelBinarizer().fit_transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2d287c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the deep network architecture\n",
    "# everywhere relu activation except output layer(sigmoid)\n",
    "model_1= Sequential()\n",
    "model_1.add(Flatten(input_shape = (28,28)))\n",
    "for i in range(10):\n",
    "    model_1.add(Dense(10))\n",
    "    model_1.add(Activation(\"relu\"))\n",
    "    model_1.add(BatchNormalization())\n",
    "model_1.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c347edef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                7850      \n",
      "                                                                 \n",
      " activation (Activation)     (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 10)               40        \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_2 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_3 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_4 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_4 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_5 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_5 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_6 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_6 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_7 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_7 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_8 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 10)                110       \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_9 (Batc  (None, 10)               40        \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,350\n",
      "Trainable params: 9,150\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60f2f441",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training the model using adam\n",
    "batch_size = 64\n",
    "model_1.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e55d4caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 4s 3ms/step - loss: 0.4169 - accuracy: 0.8937 - val_loss: 0.3725 - val_accuracy: 0.9042\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4175 - accuracy: 0.8934 - val_loss: 0.3704 - val_accuracy: 0.9039\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4155 - accuracy: 0.8935 - val_loss: 0.3643 - val_accuracy: 0.9048\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4085 - accuracy: 0.8958 - val_loss: 0.3637 - val_accuracy: 0.9050\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4022 - accuracy: 0.8981 - val_loss: 0.3612 - val_accuracy: 0.9049\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3966 - accuracy: 0.8995 - val_loss: 0.3598 - val_accuracy: 0.9090\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3973 - accuracy: 0.8988 - val_loss: 0.3577 - val_accuracy: 0.9078\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3927 - accuracy: 0.8994 - val_loss: 0.3532 - val_accuracy: 0.9072\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3837 - accuracy: 0.9019 - val_loss: 0.3545 - val_accuracy: 0.9085\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3858 - accuracy: 0.9017 - val_loss: 0.3539 - val_accuracy: 0.9072\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3810 - accuracy: 0.9012 - val_loss: 0.3448 - val_accuracy: 0.9116\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3796 - accuracy: 0.9029 - val_loss: 0.3464 - val_accuracy: 0.9098\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3776 - accuracy: 0.9036 - val_loss: 0.3462 - val_accuracy: 0.9088\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3767 - accuracy: 0.9035 - val_loss: 0.3420 - val_accuracy: 0.9122\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3737 - accuracy: 0.9034 - val_loss: 0.3407 - val_accuracy: 0.9115\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3655 - accuracy: 0.9053 - val_loss: 0.3411 - val_accuracy: 0.9096\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3664 - accuracy: 0.9054 - val_loss: 0.3431 - val_accuracy: 0.9102\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3588 - accuracy: 0.9074 - val_loss: 0.3391 - val_accuracy: 0.9108\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3613 - accuracy: 0.9071 - val_loss: 0.3383 - val_accuracy: 0.9115\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3608 - accuracy: 0.9072 - val_loss: 0.3367 - val_accuracy: 0.9132\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3601 - accuracy: 0.9083 - val_loss: 0.3377 - val_accuracy: 0.9121\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3574 - accuracy: 0.9082 - val_loss: 0.3319 - val_accuracy: 0.9136\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3546 - accuracy: 0.9086 - val_loss: 0.3338 - val_accuracy: 0.9119\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3547 - accuracy: 0.9089 - val_loss: 0.3293 - val_accuracy: 0.9139\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3549 - accuracy: 0.9082 - val_loss: 0.3339 - val_accuracy: 0.9116\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3525 - accuracy: 0.9100 - val_loss: 0.3306 - val_accuracy: 0.9109\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 2s 3ms/step - loss: 0.3498 - accuracy: 0.9099 - val_loss: 0.3291 - val_accuracy: 0.9130\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3506 - accuracy: 0.9091 - val_loss: 0.3285 - val_accuracy: 0.9131\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3482 - accuracy: 0.9100 - val_loss: 0.3282 - val_accuracy: 0.9129\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3436 - accuracy: 0.9104 - val_loss: 0.3303 - val_accuracy: 0.9098\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x227ecac3e50>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1.fit(Xtrain,Ytrain, epochs=30,batch_size=batch_size,validation_data=(Xtest,Ytest), shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbb0cd1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 922us/step - loss: 0.3303 - accuracy: 0.9098\n",
      "Test accuracy of model-1:  0.9097999930381775\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network on the testing data to obtain our final classifications\n",
    "test_loss_1, test_acc_1 = model_1.evaluate(Xtest,Ytest)\n",
    "print(\"Test accuracy of model-1: \", test_acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ff8c67ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 792us/step\n",
      "[0.39599073 0.99980175 0.8242614  0.04138685 0.46561313 0.02686111\n",
      " 0.68699217 0.2867865  0.8158914  0.312934  ]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#prediction on test data\n",
    "predictions = model_1.predict(Xtest)\n",
    "print(predictions[5])\n",
    "print(np.argmax(predictions[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6b30eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD4CAYAAABSUAvFAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAURUlEQVR4nO3df7AdZX3H8fcnlwDlV4VGaEyCpDRWqFPBBrCiLcgggdYGHalgB9HRRlrSyowzheEPZcZ2ivUnjpH0AhlwimYcQUmdaERGRaclTaARElIgBgqXZBIjKD/UJPfeb//YjZx7zrl79p4fd/e5+bxmdu7ZffY8+80Z5svzPPvss4oIzMxSMqvqAMzMpsqJy8yS48RlZslx4jKz5DhxmVlyDpnOix2qw+JwjpzOS5odVH7NS+yLveqljgvOPTJ+9uxYqXMfeGjvuohY0sv1utFT4pK0BLgRGAJuiYgbis4/nCM5S+f1ckkzK7A+7u25jj3PjrF+3fxS586e+5M5PV+wC10nLklDwArgfGAE2CBpTUQ80q/gzKwKwViMVx1EoV7GuM4EtkXE9ojYB6wGlvYnLDOrSgDjRKmtKr10FecBTzfsjwBnNZ8kaRmwDOBwjujhcmY2Xcapd4url8TVbgCwJQVHxDAwDHCMjvPzRWY1FwT7a95V7CVxjQALGvbnAzt6C8fMqhbAWIXdwDJ6GePaACyStFDSocClwJr+hGVmVZqxY1wRMSppObCObDrEqojY0rfIzKwSAYzVfNWYnuZxRcRaYG2fYjGzmqj3CNc0z5w3s/oLovZjXE5cZjZBBOyvd95y4jKzZmKs7Wyn+nDiMrMJAhh3i8vMUuMWl5klJZuA6sRlZgkJYH/Ue41RJy4zmyAQYzVfHNmJy8xajIe7imaWEI9xmVmCxJjHuMwsJdkKqE5cZpaQCLEvhqoOo5ATl5m1GPcYl5mlJBucd1fRzJLiwXkzS4wH580sSWOegGpmKQnE/qh3aqh3dGY27Tw4b2bJCeSuopmlx4PzZpaUCDwdwszSkg3O+5EfM0uMB+fNLCmBvJCgmaXHLS4zS0r2XkUnLjNLit9kbQe5n7/3TyYtW3/DTYXfPXXF3xWWn/iJ/y4sj9HRwnJrL3s9Wb3vKvbUHpT0pKSHJW2StLFfQZlZdSLEeMwqtZUhaYmkRyVtk3Rtm/LflvQfkn4saYuk93eqsx8trnMjYk8f6jGzmujXBFRJQ8AK4HxgBNggaU1EPNJw2lXAIxHxdkmvBB6VdEdE7Jus3nqPwJnZtMvW41KprYQzgW0RsT1PRKuBpW0uebQkAUcBzwKF/fxeW1wBfEdSAP8WEcPNJ0haBiwDOJwjerycmQ3elFZAndM0TDTclAfmAU837I8AZzXV8QVgDbADOBp4d0SMF12018R1dkTskHQ8cI+k/42I+xpPyP8RwwDH6Ljo8XpmNmDZdIjSdxX3RMTigvJ2FTXngQuATcBbgZPJcskPI+L5ySrtqasYETvyv7uBr5M1C80sYQeeVSyzlTACLGjYn0/Wsmr0fuCuyGwDngBeW1Rp14lL0pGSjj7wGXgbsLnb+sysPsaZVWorYQOwSNJCSYcCl5J1Cxs9BZwHIOkE4A+A7UWV9tJVPAH4ejaexiHAlyPi2z3UZwk6ZN6rCss//tFbuq77kau+WFh+4effUlgeL7zQ9bUPZtmyNv2ZgBoRo5KWA+uAIWBVRGyRdGVevhL4OHCbpIfJupbXdJqp0HXiiojtwOu7/b6Z1Vc/H7KOiLXA2qZjKxs+7yDrsZXmmfNmNkG2OkS9Z0o5cZnZBNkjP05cZpYUt7jMLEElZ8VXxonLzCbo513FQXHisp7svuDVheVvO2J/13W/YeO7C8tf+eJjXddtxdxVNLOkeM15M0tOAKNucZlZatxVNLO0hLuKZpaYAwsJ1pkTl5m1cIvLzJIyxYUEK+HEZYVmHVG83PYF//CjgV37sNXHFp8QXlB3EAIxOu7BeTNLjMe4zCwt4a6imSXGY1xmliQnLjNLSiDGPDhvZqnx4LyZJSU8OG+p2/umUwrL/+n4W7uu+5fj+wrLj/ny/V3Xbb0JJy4zS4sfsjazBLnFZWZJiYCxcScuM0uM7yqaWVICdxXNLDkenDezBNV9xSAnLiv0xDuHBlb3ux6/uMMZOwZ2bStW965ixweSJK2StFvS5oZjx0m6R9Lj+d8OK76ZWSqyu4qzSm1VKXPl24AlTceuBe6NiEXAvfm+mc0QEeW2qnRMXBFxH/Bs0+GlwO3559uBi/sblplVKUKltqp0O8Z1QkTsBIiInZKOn+xEScuAZQCHU7x+uZlVL6g2KZUx8E5qRAxHxOKIWDybwwZ9OTPrgyi5VaXbxLVL0lyA/O/u/oVkZpUKiHGV2sqQtETSo5K2SWo7Hi7pHEmbJG2R9INOdXabuNYAV+SfrwDu7rIeM6uhfo1xSRoCVgAXAqcCl0k6temcVwBfBP4yIv4QuKRTvR3HuCR9BTgHmCNpBPgYcAPwVUkfAJ4qcyFL05+f8eOevv+L8V9NWrb/+hMKvzvL87gq08c7hmcC2yJiO4Ck1WQ39x5pOOc9wF0R8VR27ejYg+uYuCLiskmKzuv0XTNLzxSfVZwjaWPD/nBEDDfszwOebtgfAc5qquM1wGxJ3weOBm6MiC8VXdQz581sogDKJ649EbG4oLxdRc3tuUOAPyZrDP0W8F+S7o+Ixyar1InLzFr0sas4Aixo2J9P67NcI2QJ8CXgJUn3Aa8HJk1c9X4HkZlVoNwdxZJ3FTcAiyQtlHQocCnZzb1GdwNvkXSIpCPIupJbiyp1i8vMWvWpxRURo5KWA+uAIWBVRGyRdGVevjIitkr6NvAQMA7cEhGbJ6/VicvMmkV/V4eIiLXA2qZjK5v2Pwl8smydTlwHub0XnVFY/oV5N/dU/8jo5GWzfvA/PdVtA+T1uMwsPfV+VtGJy8xajVcdQDEnLjObaGrzuCrhxGVmLbzmvJmlx4nLzJLjrqKZpUZucVmd7Tpj9kDrf/s3r560bBHrB3pt61IISi4SWBUnLjNr5RaXmSXHicvMkuPEZWZJ8QRUM0uR7yqaWXqcuMwsNW5xWa0devpzPX1/675fFpa/9vN7Ji0b6+nKNlAe4zKzpATuKppZgpy4zCw18kKCZpYct7jMLCUK31U0sxT5rqKZJcctLqvSr//izMLyjWfc1KGGocLSR/cfX1g+9thPOtRvdVT3ruKsTidIWiVpt6TNDceul/SMpE35dtFgwzSzaRPZXcUyW1U6Ji7gNmBJm+OfjYjT8m1tm3IzS1WU3CrSMXFFxH3As9MQi5nVReqJq8BySQ/lXcljJztJ0jJJGyVt3M/eHi5nZtPlwJSITltVuk1cNwEnA6cBO4FPT3ZiRAxHxOKIWDybw7q8nJnZy7pKXBGxKyLGImIcuBkovnVlZmmZiV1FSXMbdt8BbJ7sXDNLTAJ3FTvO45L0FeAcYI6kEeBjwDmSTiPLuU8CHxpciNaLX80pnoc1W8XlnfzjA+8sLF/IQz3VbxWp+TyujokrIi5rc/jWAcRiZjUgZsAEVDM7CPVxjEvSEkmPStom6dqC886QNCbpXZ3qdOIys4lKToUo0yqTNASsAC4ETgUuk3TqJOd9AlhXJkQnLjNrNV5y6+xMYFtEbI+IfcBqYGmb8/4euBPYXaZSJy4zazGFFtecAxPM821ZU1XzgKcb9kfyYy9fS5pHNjthZdn4vDqEmbUqPzi/JyIWF5S3W9irufbPAddExJhUbh0wJ64Zbu/FP+/p+51ePzb/ltk91W811N/JpSPAgob9+cCOpnMWA6vzpDUHuEjSaER8Y7JKnbjMrEUfp0NsABZJWgg8A1wKvKfxhIhY+JvrSrcB3yxKWuDEZWbt9ClxRcSopOVkdwuHgFURsUXSlXl56XGtRk5cZtain4/z5Ov1rW061jZhRcT7ytTpxGVmE/lN1maWGtH+VmCdOHGZWSu3uMwsNXV/yNqJawYYes3Jk5ZtPOPfO327sPRbL76usHz2dx/oUL8lyYnLzJIS1S4SWIYTl5m1covLzFLjMS4zS48Tl5mlxi0uM0tLUHaRwMo4cZnZBCm8LMOJawbYde7xk5b1+vqxL3zv/MLyRazvqX6rKScuM0uNot6Zy4nLzCby6hBmliKPcZlZcvzIj5mlxy0uM0tKybdUV8mJy8xaOXHZoP36uO4X2n1g777C8lM+MVJYPtr1la2uUpiAOqvTCZIWSPqepK2Stkj6cH78OEn3SHo8/3vs4MM1s+mg8Si1VaVj4iL7n+pHIuIU4I3AVZJOBa4F7o2IRcC9+b6ZpS6msFWkY+KKiJ0R8WD++QVgKzAPWArcnp92O3DxgGI0s2mm8XJbVaY0xiXpJOB0YD1wQkTshCy5SWr7wJykZcAygMM5oqdgzWya1HyMq3TiknQUcCdwdUQ8L5UbEI6IYWAY4BgdV/Ofw8xgBgzOA0iaTZa07oiIu/LDuyTNzcvnArsHE6KZTasAIsptFenY4lLWtLoV2BoRn2koWgNcAdyQ/717IBFaR8e/9Zmuv7vm+dMLy8d+uqfrui1dM+GRn7OBy4GHJW3Kj11HlrC+KukDwFPAJQOJ0MymVQrzuDomroj4Edm/pZ3z+huOmVWu4m5gGZ45b2Ytkm9xmdlByInLzFLjFpeZpSWAsXpnLicuM2vhFpf1TIcdVli+9FU/7rrun+07qrA89u7tum5LWB/vKkpaAtwIDAG3RMQNTeV/DVyT774I/G1EFP5H7cRlZi361eKSNASsAM4HRoANktZExCMNpz0B/FlEPCfpQrJHBM8qqrfUIz9mdhDp77I2ZwLbImJ7ROwDVpOtLPPy5SL+MyKey3fvB+Z3qtQtLjObQIDKD87PkbSxYX84X1jhgHnA0w37IxS3pj4AfKvTRZ24zKzFFN5kvSciFhdV1eZY28olnUuWuN7c6aJOXGY2UX9XNx0BFjTszwd2NJ8k6Y+AW4ALI+JnnSr1GJeZNSm5pE25VtkGYJGkhZIOBS4lW1nmNySdCNwFXB4Rj5Wp1C0uM2vRr7uKETEqaTmwjmw6xKqI2CLpyrx8JfBR4HeAL+YLlI526H46cSVhbKyweHjr5EMCV7/pycLvfv/p3y8sn8eWwnKbofo4jysi1gJrm46tbPj8QeCDU6nTicvMJoop3VWshBOXmbWqd95y4jKzVlOYDlEJJy4za+XEZWZJCWAGvCzDzA4iItxVNLMEjde7yeXElYAYHS0sP+nalyYtO+VfLi/8rjYd3VVMNoO5q2hmKXJX0czS48RlZmnxC2HNLDV+y4+ZpchjXGaWHicuM0tKAOOJJy5JC4AvAb9LNrtjOCJulHQ98DfAT/NTr8vX3bFpNrbtiUnLTrxkGgOxGWJmDM6PAh+JiAclHQ08IOmevOyzEfGpwYVnZpVIPXFFxE5gZ/75BUlbyV45ZGYzUQBj9Z46P6WXZUg6CTgdWJ8fWi7pIUmrJB07yXeWSdooaeN+/Dp3s/oLiPFyW0VKJy5JRwF3AldHxPPATcDJwGlkLbJPt/teRAxHxOKIWDybw3qP2MwGr39v+RmIUncVJc0mS1p3RMRdABGxq6H8ZuCbA4nQzKZXAncVO7a4lL0v6FZga0R8puH43IbT3gFs7n94ZlaJGdDiOhu4HHhY0qb82HXAZZJOI8vPTwIfGkB8ZlaFGXBX8UeA2hR5zpbZTBTR8V2eVfPMeTNrlXqLy8wOQk5cZpaWqP1dRScuM5soICqcXFqGE5eZtar5Iz9OXGY2UYRfT2ZmCfLgvJmlJtziMrO0zIyFBM3sYJLAQ9ZOXGY2QQBR80d+prSQoJkdBKK/CwlKWiLpUUnbJF3bplySPp+XPyTpDZ3qdIvLzFpEn7qKkoaAFcD5wAiwQdKaiHik4bQLgUX5dhbZIqVnFdXrFpeZtepfi+tMYFtEbI+IfcBqYGnTOUuBL0XmfuAVTev9tZjWFtcLPLfnu/G1/2s4NAfYM50xTEFdY6trXODYutXP2F7dawUv8Ny678bX5pQ8/XBJGxv2hyNiuGF/HvB0w/4Ira2pdufMI39JTzvTmrgi4pWN+5I2RsTi6YyhrLrGVte4wLF1q26xRcSSPlbXbi2/5n5omXMmcFfRzAZpBFjQsD8f2NHFORM4cZnZIG0AFklaKOlQ4FJgTdM5a4D35ncX3wj8In+f66Sqvqs43PmUytQ1trrGBY6tW3WOrScRMSppObAOGAJWRcQWSVfm5SvJloG/CNgG/BJ4f6d6FTWf2m9m1sxdRTNLjhOXmSWnksTV6RGAKkl6UtLDkjY1zU+pIpZVknZL2txw7DhJ90h6PP97bI1iu17SM/lvt0nSRRXFtkDS9yRtlbRF0ofz45X+dgVx1eJ3S8m0j3HljwA8RsMjAMBlTY8AVEbSk8DiiKh8sqKkPwVeJJtV/Lr82L8Cz0bEDXnSPzYirqlJbNcDL0bEp6Y7nqbY5gJzI+JBSUcDDwAXA++jwt+uIK6/oga/W0qqaHGVeQTAgIi4D3i26fBS4Pb88+1k/+FPu0liq4WI2BkRD+afXwC2ks3ErvS3K4jLpqiKxDXZ9P66COA7kh6QtKzqYNo44cAcl/zv8RXH02x5/oT/qqq6sY0knQScDqynRr9dU1xQs9+t7qpIXFOe3j/Nzo6IN5A9sX5V3iWycm4CTgZOI3vO7NNVBiPpKOBO4OqIeL7KWBq1iatWv1sKqkhcU57eP50iYkf+dzfwdbKubZ3sOvDkfP53d8Xx/EZE7IqIscheynczFf52kmaTJYc7IuKu/HDlv127uOr0u6WiisRV5hGASkg6Mh80RdKRwNuAzcXfmnZrgCvyz1cAd1cYywRNS5G8g4p+O0kCbgW2RsRnGooq/e0mi6suv1tKKpk5n9/u/RwvPwLwz9MeRBuSfo+slQXZ41BfrjI2SV8BziFb9mQX8DHgG8BXgROBp4BLImLaB8knie0csu5OAE8CH+r0zNmAYnsz8EPgYeDAolHXkY0nVfbbFcR1GTX43VLiR37MLDmeOW9myXHiMrPkOHGZWXKcuMwsOU5cZpYcJy4zS44Tl5kl5/8Bs/vRl3QGdN0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Showing the testing input\n",
    "plt.figure()\n",
    "plt.imshow(Xtest[5])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "074ba73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model -2 => sigmoid activation everywhere\n",
    "model_2= Sequential()\n",
    "model_2.add(Flatten(input_shape = (28,28)))\n",
    "for i in range(10):\n",
    "    model_2.add(Dense(10))\n",
    "    model_2.add(Activation(\"sigmoid\"))\n",
    "    model_2.add(BatchNormalization())\n",
    "model_2.add(Dense(10,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71dc0b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 10)                7850      \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_10 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_11 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_12 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_13 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_14 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_15 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_16 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_17 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_18 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      " activation_19 (Activation)  (None, 10)                0         \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 10)               40        \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 10)                110       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 9,350\n",
      "Trainable params: 9,150\n",
      "Non-trainable params: 200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9a904062",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=Adam(learning_rate=0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0be6b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "938/938 [==============================] - 5s 3ms/step - loss: 1.6506 - accuracy: 0.4771 - val_loss: 1.1720 - val_accuracy: 0.7224\n",
      "Epoch 2/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 1.0117 - accuracy: 0.7574 - val_loss: 0.7926 - val_accuracy: 0.8334\n",
      "Epoch 3/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.7327 - accuracy: 0.8297 - val_loss: 0.5671 - val_accuracy: 0.8764\n",
      "Epoch 4/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.5755 - accuracy: 0.8568 - val_loss: 0.4559 - val_accuracy: 0.8903\n",
      "Epoch 5/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4920 - accuracy: 0.8707 - val_loss: 0.3954 - val_accuracy: 0.8976\n",
      "Epoch 6/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4411 - accuracy: 0.8803 - val_loss: 0.3573 - val_accuracy: 0.9057\n",
      "Epoch 7/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.4107 - accuracy: 0.8853 - val_loss: 0.3329 - val_accuracy: 0.9079\n",
      "Epoch 8/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3902 - accuracy: 0.8899 - val_loss: 0.3154 - val_accuracy: 0.9120\n",
      "Epoch 9/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3708 - accuracy: 0.8943 - val_loss: 0.3023 - val_accuracy: 0.9134\n",
      "Epoch 10/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3590 - accuracy: 0.8971 - val_loss: 0.2913 - val_accuracy: 0.9163\n",
      "Epoch 11/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3468 - accuracy: 0.9005 - val_loss: 0.2789 - val_accuracy: 0.9198\n",
      "Epoch 12/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3356 - accuracy: 0.9033 - val_loss: 0.2729 - val_accuracy: 0.9221\n",
      "Epoch 13/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3267 - accuracy: 0.9049 - val_loss: 0.2641 - val_accuracy: 0.9230\n",
      "Epoch 14/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3195 - accuracy: 0.9075 - val_loss: 0.2569 - val_accuracy: 0.9250\n",
      "Epoch 15/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3084 - accuracy: 0.9107 - val_loss: 0.2481 - val_accuracy: 0.9273\n",
      "Epoch 16/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.3070 - accuracy: 0.9108 - val_loss: 0.2441 - val_accuracy: 0.9280\n",
      "Epoch 17/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2961 - accuracy: 0.9139 - val_loss: 0.2392 - val_accuracy: 0.9299\n",
      "Epoch 18/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2925 - accuracy: 0.9144 - val_loss: 0.2338 - val_accuracy: 0.9317\n",
      "Epoch 19/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2824 - accuracy: 0.9173 - val_loss: 0.2297 - val_accuracy: 0.9338\n",
      "Epoch 20/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2813 - accuracy: 0.9174 - val_loss: 0.2253 - val_accuracy: 0.9346\n",
      "Epoch 21/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2795 - accuracy: 0.9171 - val_loss: 0.2232 - val_accuracy: 0.9345\n",
      "Epoch 22/30\n",
      "938/938 [==============================] - 2s 2ms/step - loss: 0.2702 - accuracy: 0.9212 - val_loss: 0.2173 - val_accuracy: 0.9362\n",
      "Epoch 23/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2670 - accuracy: 0.9212 - val_loss: 0.2166 - val_accuracy: 0.9366\n",
      "Epoch 24/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2625 - accuracy: 0.9221 - val_loss: 0.2149 - val_accuracy: 0.9378\n",
      "Epoch 25/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2580 - accuracy: 0.9241 - val_loss: 0.2106 - val_accuracy: 0.9393\n",
      "Epoch 26/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2584 - accuracy: 0.9234 - val_loss: 0.2081 - val_accuracy: 0.9407\n",
      "Epoch 27/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2590 - accuracy: 0.9235 - val_loss: 0.2082 - val_accuracy: 0.9390\n",
      "Epoch 28/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2505 - accuracy: 0.9259 - val_loss: 0.2071 - val_accuracy: 0.9404\n",
      "Epoch 29/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2498 - accuracy: 0.9258 - val_loss: 0.2032 - val_accuracy: 0.9409\n",
      "Epoch 30/30\n",
      "938/938 [==============================] - 3s 3ms/step - loss: 0.2473 - accuracy: 0.9270 - val_loss: 0.2028 - val_accuracy: 0.9419\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x22780086850>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.fit(Xtrain,Ytrain, epochs=30,batch_size=batch_size,validation_data=(Xtest,Ytest), shuffle=True, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e9c6647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 943us/step - loss: 0.2028 - accuracy: 0.9419\n",
      "Test accuracy of model-2:  0.9419000148773193\n"
     ]
    }
   ],
   "source": [
    "test_loss_2, test_acc_2 = model_2.evaluate(Xtest,Ytest)\n",
    "print(\"Test accuracy of model-2: \", test_acc_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c78195e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
